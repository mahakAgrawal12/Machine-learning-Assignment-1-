{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52c3fdb1",
   "metadata": {},
   "source": [
    "#  Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c3bdc7",
   "metadata": {},
   "source": [
    "##  we have data stored in three different csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a409f2",
   "metadata": {},
   "source": [
    "### . avocado.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9380a509",
   "metadata": {},
   "source": [
    "### . cumulative.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d338e118",
   "metadata": {},
   "source": [
    "### . iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ca517a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5658f814",
   "metadata": {},
   "source": [
    "#  Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b21639d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS : ['Id', 'AveragePrice', 'Total Volume', 'Total Bags', 'Small Bags', 'Large Bags']\n"
     ]
    }
   ],
   "source": [
    "df_avocado=pd.read_csv('DataStore/avocado.csv')\n",
    "avocado_table_columns = df_avocado.columns.tolist()\n",
    "print(f\"COLUMNS : {avocado_table_columns }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96be6869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS : ['Id', 'kepid', 'kepoi_name', 'koi_period']\n"
     ]
    }
   ],
   "source": [
    "df_cumulative=pd.read_csv('DataStore/cumulative.csv')\n",
    "cumulative_table_columns = df_cumulative.columns.tolist()\n",
    "print(f\"COLUMNS : {cumulative_table_columns }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "534309fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS : ['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species']\n"
     ]
    }
   ],
   "source": [
    "df_Iris=pd.read_csv('DataStore/Iris.csv')\n",
    "Iris_table_columns = df_Iris.columns.tolist()\n",
    "print(f\"COLUMNS : {Iris_table_columns }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18a243fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is True  that the column 'Id' has unique values for all entries in iris dataframe.\n",
      "It is True  that the column 'Id' has unique values for all entries in cumulative dataframe.\n",
      "It is False  that the column 'Id' has unique values for all entries in avocado dataframe.\n"
     ]
    }
   ],
   "source": [
    "print(f\"It is {pd.Series(df_Iris['Id']).is_unique}  that the column 'Id' has unique values for all entries in iris dataframe.\")\n",
    "print(f\"It is {pd.Series(df_cumulative['Id']).is_unique}  that the column 'Id' has unique values for all entries in cumulative dataframe.\")\n",
    "print(f\"It is {pd.Series(df_avocado['Id']).is_unique}  that the column 'Id' has unique values for all entries in avocado dataframe.\")\n",
    "df_iris_sorted = df_Iris.sort_values(by=['Id'])\n",
    "df_cumulative_sorted = df_cumulative.sort_values(by=['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a3ee55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from iris dataframe...\n",
    "id=df_iris_sorted[\"Id\"].tolist()\n",
    "sepalWidthCm = df_iris_sorted[\"SepalWidthCm\"].tolist()\n",
    "SepalLengthCm = df_iris_sorted[\"SepalLengthCm\"].tolist()\n",
    "# from cumulative dataframe...\n",
    "Ids= df_cumulative_sorted[\"Id\"].tolist()\n",
    "kepids = df_cumulative_sorted[\"kepid\"].tolist()\n",
    "kepoi_name = [kepoi_name.split(\"|\") for kepoi_name in df_cumulative[\"kepoi_name\"].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "943cdc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "irisDict             = {}\n",
    "global_secondaryIndex = {}\n",
    "for idx, Id in enumerate(id):\n",
    "    irisDict[Id] = {\n",
    "        \"sepalWidthCm\" : sepalWidthCm[idx],\n",
    "        \"cumulative\" : {\n",
    "            \"Id\" : Ids[idx], \n",
    "            \"kepids\" : kepids[idx]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    global_secondaryIndex[sepalWidthCm[idx]] = id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bacda385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Writing iris Data into the disk...\n",
      "[INFO] Writing cumulative Data into the disk...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(\"[INFO] Writing iris Data into the disk...\")\n",
    "with open('DataStore/datairis.json', 'w') as fp:\n",
    "    json.dump(irisDict, fp, sort_keys=True, indent=4)\n",
    "print(\"[INFO] Writing cumulative Data into the disk...\")\n",
    "with open('DataStore/datacumulative.json', 'w') as fp:\n",
    "    json.dump(global_secondaryIndex, fp, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c061c964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
